{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cc49748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba894d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBM(nn.Module):\n",
    "    def __init__(self, n_vis, n_hid):\n",
    "        super(RBM, self).__init__()\n",
    "        self.W = nn.Parameter(torch.randn(n_hid, n_vis))\n",
    "        self.v_bias = nn.Parameter(torch.zeros(n_vis))\n",
    "        self.h_bias = nn.Parameter(torch.zeros(n_hid))\n",
    "\n",
    "    def sample_h(self, v):\n",
    "        p_h_given_v = torch.sigmoid(0.01 * torch.matmul(v, self.W.t()) + self.h_bias)\n",
    "        return torch.bernoulli(p_h_given_v)\n",
    "\n",
    "    def sample_v(self, h):\n",
    "        p_h_given_h = torch.sigmoid(0.01 * torch.matmul(h, self.W.t()) + self.v_bias)\n",
    "        # p_v_given_h = torch.sigmoid(torch.matmul(h, self.W) + self.v_bias)\n",
    "        return torch.bernoulli(p_v_given_h)\n",
    "\n",
    "    def forward(self, v):\n",
    "        h = self.sample_h(v)\n",
    "        v_recon = self.sample_v(h)\n",
    "        return h, v_recon\n",
    "\n",
    "    def free_energy(self, v):\n",
    "        vbias_term = torch.matmul(v, self.v_bias)\n",
    "        hidden_term = torch.sum(torch.log(1 + torch.exp(torch.matmul(v, self.W.t()) + self.h_bias)), dim=1)\n",
    "        return -hidden_term - vbias_term\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "09c548e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read training data\n",
    "train_labels = pd.read_excel('../mini_dataset/Training_Set/train_labels.xlsx')\n",
    "# Read test data\n",
    "test_labels = pd.read_csv('../mini_dataset/Test_Set/test_labels.csv')\n",
    "# Read validation data\n",
    "validation_labels = pd.read_csv('../mini_dataset/Validation_Set/validation_labels.csv')\n",
    "\n",
    "\n",
    "train_labels = train_labels.drop('ID', axis=1)\n",
    "train_labels = train_labels.drop('Disease_Risk', axis=1)\n",
    "\n",
    "Y_train = torch.tensor(train_labels.values)\n",
    "\n",
    "\n",
    "path = '../mini_dataset/Training_Set/train_images/'\n",
    "images = []\n",
    "\n",
    "for file in os.listdir(path):\n",
    "    if file.endswith('.png'):\n",
    "        image = cv2.imread(os.path.join(path, file))\n",
    "        image = cv2.resize(image, (28, 28))\n",
    "        image = (image - np.mean(image)) / np.std(image)\n",
    "        image = torch.from_numpy(image)\n",
    "        images.append(image)\n",
    "\n",
    "X_train = torch.stack(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d2a00b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9227/1222204941.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_dataset = torch.utils.data.TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(Y_train, dtype=torch.float32))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (32x128 and 2352x128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m data_loader:\n\u001b[1;32m     18\u001b[0m     v \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mview(batch[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m     h, v_recon \u001b[38;5;241m=\u001b[39m \u001b[43mrbm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(rbm\u001b[38;5;241m.\u001b[39mfree_energy(v) \u001b[38;5;241m-\u001b[39m rbm\u001b[38;5;241m.\u001b[39mfree_energy(v_recon))\n\u001b[1;32m     21\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m/media/soham/CorsairSSD/Studies/CSE472-Machine-learning-[LAB]/Project/Workspace/ML_project_code/retinalenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[62], line 19\u001b[0m, in \u001b[0;36mRBM.forward\u001b[0;34m(self, v)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, v):\n\u001b[1;32m     18\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_h(v)\n\u001b[0;32m---> 19\u001b[0m     v_recon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_v\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m h, v_recon\n",
      "Cell \u001b[0;32mIn[62], line 13\u001b[0m, in \u001b[0;36mRBM.sample_v\u001b[0;34m(self, h)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample_v\u001b[39m(\u001b[38;5;28mself\u001b[39m, h):\n\u001b[0;32m---> 13\u001b[0m     p_h_given_h \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;241m0.01\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_bias)\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# p_v_given_h = torch.sigmoid(torch.matmul(h, self.W) + self.v_bias)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbernoulli(p_v_given_h)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x128 and 2352x128)"
     ]
    }
   ],
   "source": [
    "# Define hyperparameters\n",
    "batch_size = 32\n",
    "learning_rate = 0.001# source: https://github.com/AmanPriyanshu/Deep-Belief-Networks-in-PyTorch/blob/main/RBM.py\n",
    "num_epochs = 10\n",
    "\n",
    "# Create data loader\n",
    "train_dataset = torch.utils.data.TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(Y_train, dtype=torch.float32))\n",
    "data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Create RBM instance and optimizer\n",
    "rbm = RBM(n_vis=28*28*3, n_hid=128)\n",
    "optimizer = torch.optim.Adam(rbm.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train RBM\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in data_loader:\n",
    "        v = batch[0].view(batch[0].size(0), -1)\n",
    "        h, v_recon = rbm(v)\n",
    "        loss = torch.mean(rbm.free_energy(v) - rbm.free_energy(v_recon))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * v.size(0)\n",
    "    print(\"Epoch {} loss: {:.4f}\".format(epoch+1, total_loss/len(data_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d25adc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "9a0bfbe1a51dd6d5a57e057038c49f600f72730721d08b5631c8cdf5ace0d4aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
